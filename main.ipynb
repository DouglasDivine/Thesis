{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
   "#!pip install scikeras -q\n",
   "#!pip install feature-engine -q\n",
   "#!pip install hyperopt -q\n",
   "#!pip install hpsklearn -q\n",
   "#!pip install tune_sklearn -q\n",
   "#!pip install mlens -q\n",
   "#!pip install shap -q\n",
    "\n",
    "#!pip install torch\n",
    "#!pip install skorch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import check_random_state\n",
    "import tensorflow as tf\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tune_sklearn import TuneSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Import basic operations and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# Import filters to remove unnecessary warnings\n",
    "from warnings import simplefilter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Import error performance measure, preprocessing etc. from sklearn\n",
    "from sklearn.model_selection import RepeatedKFold, ParameterGrid\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score, mean_absolute_error\n",
    "# Import Machine Learning Models from sklearn and other libraries\n",
    "\n",
    "import mlens \n",
    "# if there is error here uncomment the following code\n",
    "#from collections.abc import Sequence\n",
    "# then replace collections in the mlens init.py file with collections.abc\n",
    "from mlens.parallel import Learner, Transformer, Pipeline, Group, Layer, make_group\n",
    "from mlens.ensemble import BaseEnsemble\n",
    "from mlens.index import FoldIndex, FullIndex\n",
    "from mlens.utils import check_instances\n",
    "from mlens.ensemble.base import check_kwargs\n",
    "\n",
    "# Import feature importance assessment methods\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    data = pd.read_csv(data)\n",
    "    # drop duplicates\n",
    "    data = data.drop_duplicates()\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data = data.astype('float32')\n",
    "\n",
    "    # split into input (X) and output (Y) variables\n",
    "    X = data[['Cel', 'Hem', 'Lig', 'Vm%', 'Ash%', 'FC%', 'C-%',\n",
    "              'H-%', 'O-%', 'N-%', 'Size', 'HR', 'PT', 'Temp']]\n",
    "\n",
    "    #X = data[['Lig', 'Ash%', 'O-%', 'H-%', 'N-%', 'Size', 'PT']]\n",
    "    Y = data[['H/C', 'O/C', 'Oil_yield%', 'Gas_yield%', 'Char_yield%']]\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def clean_data(data:pd.DataFrame)->pd.DataFrame:\n",
    "  \"\"\"\n",
    "  A function that replaces the nan or missing values of each column with the mean value of that column respectively,\n",
    "  converts the data to the right format\n",
    "  \"\"\"\n",
    "  for col in data.columns:\n",
    "    if data[col].dtype !='float':\n",
    "      data[col] = pd.to_numeric(data[col],errors='coerce')\n",
    "  return data.fillna(data.mean())\n",
    "\n",
    "\n",
    "\n",
    "def add_features(data:pd.DataFrame):\n",
    "  df = data.copy()\n",
    "  df['Cel_Hem_lig']= data.loc[:,'Cel']+data.loc[:,'Hem']+data.loc[:,'Lig']\n",
    "  df['Cel_Hem_O']= data.loc[:,'Cel']+data.loc[:,'Hem']+data.loc[:,'O-%']\n",
    "  df['Hem_lig']= data.loc[:,'Hem']+data.loc[:,'Lig']\n",
    "  df['FC_Vm']= data.loc[:,'FC%']+data.loc[:,'Vm%']\n",
    "  df['FC_Ash']= data.loc[:,'FC%']+data.loc[:,'Ash%']\n",
    "  df['FC_Vm_Ash']= data.loc[:,'FC%']+data.loc[:,'Ash%']+data.loc[:,'Vm%']\n",
    "  df['C_O']= data.loc[:,'C-%']+data.loc[:,'O-%']\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "def outlier_threshold(normality, k=1.5):\n",
    "    # use k =1.5\n",
    "    q1 = np.quantile(normality, 0.25)\n",
    "    q3 = np.quantile(normality, 0.75)\n",
    "    threshold = q1 - k*(q3-q1)\n",
    "    return threshold\n",
    "\n",
    "\n",
    "def remove_outlier(X,Y):\n",
    "    clf = IsolationForest(\n",
    "        n_estimators=100,\n",
    "        max_samples='auto',\n",
    "        n_jobs=-1,\n",
    "        random_state=5)\n",
    "\n",
    "    clf.fit(X)\n",
    "    normality_df = pd.DataFrame(\n",
    "        clf.decision_function(X),\n",
    "        columns=['normality'])\n",
    "\n",
    "    threshold = outlier_threshold(normality_df['normality'].values, k=1.5)\n",
    "\n",
    "    # Plots the distribution and the threshold\n",
    "    fig = px.histogram(normality_df, x='normality', width=400, height=400)\n",
    "    fig.add_vline(x=threshold, line_width=3,\n",
    "                  line_dash=\"dash\", line_color=\"red\")\n",
    "    fig.update_layout(width=670, height=400)\n",
    "    fig.show()\n",
    "\n",
    "    # remove outliers from both the x and y data\n",
    "    x_new = X[normality_df['normality'].values >= threshold]\n",
    "    y_new = Y[normality_df['normality'].values >= threshold]\n",
    "    print('{} out of {} observations are removed from the dataset'.format(\n",
    "        (X.shape[0] - x_new.shape[0]), X.shape[0]))\n",
    "\n",
    "    return x_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_scale_data(df_feat:pd.DataFrame,df_tar:pd.DataFrame,sc:str):\n",
    "  df_features = clean_data(df_feat.copy())\n",
    "  df_target = clean_data(df_tar.copy())\n",
    "\n",
    "\n",
    "  if sc=='MS':\n",
    "    mm_X = MinMaxScaler(feature_range=(0,1))\n",
    "    mm_Y = MinMaxScaler(feature_range=(0,1))\n",
    "  if sc == 'SC':\n",
    "    mm_X = StandardScaler()\n",
    "    mm_Y = StandardScaler()\n",
    "  if sc == 'RS':\n",
    "    mm_X = RobustScaler()\n",
    "    mm_Y = RobustScaler()\n",
    "\n",
    "  X = mm_X.fit_transform(df_features)\n",
    "  Y = mm_Y.fit_transform(df_target)\n",
    "\n",
    "\n",
    "  return X,Y,mm_X,mm_Y\n",
    "\n",
    "def post_scale_data(mm_X,mm_Y,df_X,df_Y):\n",
    "  df_post_X = mm_X.inverse_transform(df_X)\n",
    "  df_post_Y = mm_Y.inverse_transform(df_Y)\n",
    "\n",
    "  return df_post_X,df_post_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "for name in ['SVM', 'RF', 'XGB', 'ANN', 'GBR','ADA','SGD']:\n",
    "  model_list.append(np.full(5, name))\n",
    "\n",
    "best_cv_df = pd.DataFrame({'model': np.hstack((model_list)), 'RMSLE':None, 'best_hyper_param':None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function for multisuperlearner models\n",
    "def rmse(yreal, yhat):\n",
    " return mean_squared_error(yreal, yhat,squared=False)\n",
    "\n",
    "# First, your new Learner. ``num_targets`` will be your multi-output dimensionality.\n",
    "\n",
    "class MultiLearner(Learner):\n",
    "\n",
    "    def __init__(self, estimator, num_targets, **kwargs):\n",
    "        super(MultiLearner, self).__init__(estimator, **kwargs)\n",
    "        self.num_targets = num_targets\n",
    "\n",
    "    def _get_multiplier(self, X, y):\n",
    "        return self.num_targets\n",
    "\n",
    "\n",
    "def make_multi_group(indexer, estimators, preprocessing,\n",
    "                     learner_kwargs=None, transformer_kwargs=None, name=None):\n",
    "    preprocessing, estimators = check_instances(estimators, preprocessing)\n",
    "\n",
    "    if learner_kwargs is None:\n",
    "        learner_kwargs = {}\n",
    "    if transformer_kwargs is None:\n",
    "        transformer_kwargs = {}\n",
    "\n",
    "    transformers = [Transformer(estimator=Pipeline(tr, return_y=True),\n",
    "                                name=case_name, **transformer_kwargs)\n",
    "                    for case_name, tr in preprocessing]\n",
    "\n",
    "    # We use your new MultiLearner class here\n",
    "    learners = [MultiLearner(estimator=est, preprocess=case_name,\n",
    "                        name=learner_name, **learner_kwargs)\n",
    "                for case_name, learner_name, est in estimators]\n",
    "\n",
    "    group = Group(indexer=indexer, learners=learners,\n",
    "                  transformers=transformers, name=name)\n",
    "    return group\n",
    "\n",
    "\n",
    "# Change the make_group function in the base ensemble class\n",
    "\n",
    "\n",
    "class MultiBaseEnsemble(BaseEnsemble):\n",
    "\n",
    "    def _build_layer(self, estimators, indexer, preprocessing, **kwargs):\n",
    "        check_kwargs(kwargs, ['backend', 'n_jobs'])\n",
    "        verbose = kwargs.pop('verbose', max(self._backend.verbose - 1, 0))\n",
    "        dtype = kwargs.pop('dtype', self._backend.dtype)\n",
    "        propagate = kwargs.pop('propagate_features', None)\n",
    "        shuffle = kwargs.pop('shuffle', self.shuffle)\n",
    "        random_state = kwargs.pop('random_state', self.random_state)\n",
    "        rs = kwargs.pop('raise_on_exception', self.raise_on_exception)\n",
    "        if random_state:\n",
    "            random_state = check_random_state(random_state).randint(0, 10000)\n",
    "\n",
    "        kwargs['verbose'] = max(verbose - 1, 0)\n",
    "        kwargs['scorer'] = kwargs.pop('scorer', self.scorer)\n",
    "\n",
    "        # We use your make_multi_group function from above\n",
    "        group = make_multi_group(indexer, estimators, preprocessing, kwargs)\n",
    "\n",
    "        name = \"layer-%i\" % (len(self._backend.stack) + 1)  # Start count at 1\n",
    "        lyr = Layer(\n",
    "            name=name, dtype=dtype, shuffle=shuffle,\n",
    "            random_state=random_state, verbose=verbose,\n",
    "            raise_on_exception=rs, propagate_features=propagate)\n",
    "        lyr.push(group)\n",
    "        return lyr\n",
    "\n",
    "\n",
    "# Finally, build the MultiSuperLearner (or similar)\n",
    "\n",
    "class MultiSuperLearner(MultiBaseEnsemble):\n",
    "\n",
    "    def __init__(\n",
    "            self, folds=2, shuffle=False, random_state=None, scorer=None,\n",
    "            raise_on_exception=True, array_check=None, verbose=False, n_jobs=-1,\n",
    "            backend='threading', model_selection=False, sample_size=20, layers=None):\n",
    "        super(MultiSuperLearner, self).__init__(\n",
    "            shuffle=shuffle, random_state=random_state, scorer=scorer,\n",
    "            raise_on_exception=raise_on_exception, verbose=verbose,\n",
    "            n_jobs=n_jobs, layers=layers, backend=backend,\n",
    "            array_check=array_check, model_selection=model_selection,\n",
    "            sample_size=sample_size)\n",
    "\n",
    "        self.__initialized__ = 0  # Unlock parameter setting\n",
    "        self.folds = folds\n",
    "        self.__initialized__ = 1  # Protect against param resets\n",
    "\n",
    "    def add_meta(self, estimator, **kwargs):\n",
    "        return self.add(estimators=estimator, meta=True, **kwargs)\n",
    "\n",
    "    def add(self, estimators, num_targets=1, preprocessing=None,\n",
    "            proba=False, meta=False, propagate_features=None, **kwargs):\n",
    "        c = kwargs.pop('folds', self.folds)\n",
    "\n",
    "        if meta:\n",
    "            idx = FullIndex()\n",
    "        else:\n",
    "            idx = FoldIndex(c, raise_on_exception=self.raise_on_exception)\n",
    "\n",
    "        return super(MultiSuperLearner, self).add(\n",
    "            estimators=estimators, num_targets=num_targets, indexer=idx, preprocessing=preprocessing,\n",
    "            proba=proba, propagate_features=propagate_features, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error_percent(prediction, y):\n",
    "  \"\"\"\n",
    "  A function to calculate the relative error percent between the predicted value and actual values\n",
    "  \"\"\"\n",
    "  rel_error = 2 * np.absolute(y - prediction) / (np.absolute(y) + np.absolute(prediction))\n",
    "\n",
    "  return rel_error*100\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def get_scores(X,Y,opt=False):\n",
    "  complete_score = pd.DataFrame()\n",
    "  models = ['SVM', 'RF', 'XGB', 'ANN', 'GBR','ADA','SGD']\n",
    "  for modelname in models :\n",
    "    if opt == False:\n",
    "      performance =build_models(X,Y,test_fraction =0.15, modelname = modelname, random_state = 42, CV_folds = 5, optimisation = opt, display = False)\n",
    "      complete_score = pd.concat([complete_score,performance],axis=0)\n",
    "    if opt == True:\n",
    "      if modelname != 'SVM':\n",
    "        performance =build_models(X,Y,test_fraction =0.14, modelname = modelname, random_state = 42, CV_folds = 5, optimisation = opt, display = False)\n",
    "        complete_score = pd.concat([complete_score,performance],axis=0)\n",
    "\n",
    "  complete_score.dropna(axis=1,inplace=True)\n",
    "  if opt == True:\n",
    "    complete_score.index = ['RF', 'XGB', 'ANN', 'GBR','ADA','SGD']\n",
    "  else:\n",
    "    complete_score.index = models\n",
    "\n",
    "\n",
    "  return complete_score\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def plot_correlation(data:np,cols=['Cel', 'Hem', 'Lig', 'Vm%', 'Ash%', 'FC%', 'C-%', 'H-%', 'O-%', 'N-%','Size','HR', 'PT', 'Temp']):\n",
    "  \"\"\"\n",
    "  Function that shows the correlation and clustering between the features:\n",
    "\n",
    "  \"\"\"\n",
    "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 6))\n",
    "  corr = spearmanr(X).correlation\n",
    "\n",
    "  # Ensure the correlation matrix is symmetric\n",
    "  corr = (corr + corr.T) / 2\n",
    "  np.fill_diagonal(corr, 1)\n",
    "  # We convert the correlation matrix to a distance matrix before performing\n",
    "  # hierarchical clustering using Ward's linkage.\n",
    "  distance_matrix = 1 - np.abs(corr)\n",
    "  dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
    "  dendro = hierarchy.dendrogram(\n",
    "      dist_linkage, labels=cols, ax=ax1, leaf_rotation=90\n",
    "  )\n",
    "  dendro_idx = np.arange(0, len(dendro[\"ivl\"]))\n",
    "\n",
    "  ax2.imshow(corr[dendro[\"leaves\"], :][:, dendro[\"leaves\"]])\n",
    "  ax2.set_xticks(dendro_idx)\n",
    "  ax2.set_yticks(dendro_idx)\n",
    "  ax2.set_xticklabels(dendro[\"ivl\"], rotation=\"vertical\")\n",
    "  ax2.set_yticklabels(dendro[\"ivl\"])\n",
    "  fig.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def plot_train_set(y_train_df:pd.DataFrame,y_train_pred_df:pd.DataFrame,y_test_df:pd.DataFrame,y_test_pred_df:pd.DataFrame):\n",
    "  \"\"\" A function that plots the comparison of the predictions of the various target variables for a ML models\n",
    "      fitted from the training set and testing set.\n",
    "      params:\n",
    "      y_train_df: A dataframe containing the original training dataset\n",
    "      y_train_pred_df: A dataframe containing the predictions for the training dataset,\n",
    "      y_test_df:  A dataframe containing the original testing dataset\n",
    "      y_test_pred_df: A dataframe containing the predictions for the testing dataset\n",
    "  \"\"\"\n",
    "\n",
    "  plt.rcParams.update({'font.size': 10})\n",
    "  fig=plt.figure(figsize=(15,7))\n",
    "  spec = mpl.gridspec.GridSpec(ncols=6, nrows=2) # 6 columns evenly divides both 2 & 3\n",
    "  ax1 = fig.add_subplot(spec[0,0:2]) # row 0 with axes spanning 2 cols on evens\n",
    "  ax2 = fig.add_subplot(spec[0,2:4])\n",
    "  ax3 = fig.add_subplot(spec[0,4:])\n",
    "  ax4 = fig.add_subplot(spec[1,1:3]) # row 0 with axes spanning 2 cols on odds\n",
    "  ax5 = fig.add_subplot(spec[1,3:5])\n",
    "  all_axis = [ax1,ax2,ax3,ax4,ax5]\n",
    "  for val in zip(y_train_df.columns,all_axis):\n",
    "    col,graph = list(val)\n",
    "    graph.scatter(y_train_df[col], y_train_pred_df[col])\n",
    "    graph.scatter(x=y_test_df[col], y=y_test_pred_df[col],color='red',marker='o')\n",
    "    # add straight line\n",
    "    line = np.linspace(np.min(y_train_df.to_numpy()),np.max(y_train_df.to_numpy()))\n",
    "    graph.plot(line, line, linewidth=1.5,color='orange', zorder=4)\n",
    "    graph.set_ylim(ymin=0,ymax=1.01)\n",
    "    graph.set_xlim(xmin=0,xmax=1.01)\n",
    "    # Add error regions\n",
    "    graph.fill_between(line, line - 0.12, line + 0.12, color='grey',linestyle='dashed',alpha = 0.05) # 12% error\n",
    "    #ax1.fill_between(line, line - 0.2, line + 0.2,color ='blue',linestyle='dashed', alpha = 0.05) # 20% error\n",
    "    # set labels\n",
    "    graph.set(xlabel=f'Measured {col}', ylabel=f'Predicted {col}')\n",
    "    graph.legend(loc='upper left', labels=['X - Y','Training Set', 'Testing Set','12% deviation line'])\n",
    "    plt.tight_layout()\n",
    "  plt.show()\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def plot_feat_importance(model,y_train_df,x_cols):\n",
    "\n",
    "  cols = x_cols\n",
    "  y_cols = y_train_df.columns\n",
    "  fig=plt.figure(figsize=(15,8))\n",
    "  spec = mpl.gridspec.GridSpec(ncols=6, nrows=2) # 6 columns evenly divides both 2 & 3\n",
    "  ax1 = fig.add_subplot(spec[0,0:2]) # row 0 with axes spanning 2 cols on evens\n",
    "  ax2 = fig.add_subplot(spec[0,2:4])\n",
    "  ax3 = fig.add_subplot(spec[0,4:])\n",
    "  ax4 = fig.add_subplot(spec[1,1:3]) # row 0 with axes spanning 2 cols on odds\n",
    "  ax5 = fig.add_subplot(spec[1,3:5])\n",
    "  all_axis = [ax1,ax2,ax3,ax4,ax5]\n",
    "  ### Get the feature importance for each target\n",
    "  for val in zip(range(len(model.estimators_)),all_axis):\n",
    "    i,graph = list(val)\n",
    "    feature_importance = model.estimators_[i].feature_importances_\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    graph.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "    graph.set_yticks(range(len(sorted_idx)))\n",
    "    graph.set_yticklabels(np.array(cols)[sorted_idx])\n",
    "    graph.set(xlabel=f'Feature Importance for {y_cols[i]}', ylabel='Feature names')\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "def plot_perm_feat_importance(model,y_train_df,x_cols,X_train,y_train):\n",
    "\n",
    "  cols = x_cols\n",
    "  y_cols = y_train_df.columns\n",
    "  result = permutation_importance(model, X_train, y_train, n_repeats=10,n_jobs=2,random_state=42)\n",
    "  perm_sorted_idx = result.importances_mean.argsort()\n",
    "  tree_importance_sorted_idx = np.argsort(model.estimators_[0].feature_importances_)\n",
    "  tree_indices = np.arange(0, len(model.estimators_[0].feature_importances_)) + 0.5\n",
    "\n",
    "  fig=plt.figure(figsize=(15,8))\n",
    "  spec = mpl.gridspec.GridSpec(ncols=6, nrows=2) # 6 columns evenly divides both 2 & 3\n",
    "  ax1 = fig.add_subplot(spec[0,0:2]) # row 0 with axes spanning 2 cols on evens\n",
    "  ax2 = fig.add_subplot(spec[0,2:4])\n",
    "  ax3 = fig.add_subplot(spec[0,4:])\n",
    "  ax4 = fig.add_subplot(spec[1,1:3]) # row 0 with axes spanning 2 cols on odds\n",
    "  ax5 = fig.add_subplot(spec[1,3:5])\n",
    "  all_axis = [ax1,ax2,ax3,ax4,ax5]\n",
    "  ### Get the feature importance for each target\n",
    "  for val in zip(range(len(model.estimators_)),all_axis):\n",
    "    i,graph = list(val)\n",
    "    graph.boxplot(\n",
    "      result.importances[perm_sorted_idx].T,\n",
    "      vert=False,\n",
    "      labels=np.array(cols)[perm_sorted_idx],\n",
    "  )\n",
    "    graph.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "    graph.set(xlabel=f'Permutation Feature Importance for {y_cols[i]}', ylabel='Feature names')\n",
    "  fig.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def plot_errors(y_train_df,y_train_pred_df,y_test_df ,y_test_pred_df):\n",
    "  err_train = relative_error_percent(y_train_pred_df,y_train_df)\n",
    "  err_test = relative_error_percent(y_test_pred_df,y_test_df)\n",
    "  cols = y_train_df.columns  # get target columns\n",
    "  # Create Subplots\n",
    "  fig = make_subplots(rows=1, cols=2)\n",
    "  #  Plots errors for each target in train data\n",
    "\n",
    "  for xd in cols:\n",
    "    fig.add_trace(go.Box(\n",
    "        y=err_train[xd],\n",
    "        name=xd,\n",
    "        boxpoints='all',\n",
    "        marker_size=2,\n",
    "        ), row=1, col=1\n",
    "    )\n",
    "\n",
    "    #  Plots errors for each target in test data\n",
    "\n",
    "  for xd in cols:\n",
    "    fig.add_trace(go.Box(\n",
    "        y=err_test[xd],\n",
    "        name=xd,\n",
    "        boxpoints='all',\n",
    "        marker_size=2,\n",
    "        ), row=1, col=2\n",
    "    )\n",
    "  # Update the plots layout\n",
    "  fig.update_xaxes(showline = True, linecolor = 'black', linewidth = 1, row = 1, col = 1, mirror = True)\n",
    "  fig.update_yaxes(showline = True, linecolor = 'black', linewidth = 1, row = 1, col = 1, mirror = True,title_text = \"Relative error (%)\",)\n",
    "  fig.update_xaxes(showline = True, linecolor = 'black', linewidth = 1, row = 1, col = 2, mirror = True)\n",
    "  fig.update_yaxes(showline = True, linecolor = 'black', linewidth = 1, row = 1, col = 2, mirror = True,title_text = \"Relative error (%)\",)\n",
    "\n",
    "  fig.update_layout(plot_bgcolor=\"#FFFFFF\",width=1000,height=450,showlegend=False)\n",
    "  fig.show()\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "def plot_shap_importances(model_norm,x_train, x_test, y_train, y_test,x_cols,y_cols=['H/C','O/C','Oil_yield%','Gas_yield%','Char_yield%']):\n",
    "  \"\"\"\n",
    "    Plot the SHAP importances for a given model and dataset.\n",
    "\n",
    "    Args:\n",
    "    model_norm (sklearn estimator): A fitted sklearn estimator for multi-output regression.\n",
    "    x_train (numpy array or pandas DataFrame): Training set features.\n",
    "    x_test (numpy array or pandas DataFrame): Test set features.\n",
    "    y_train (numpy array or pandas DataFrame): Training set targets.\n",
    "    y_test (numpy array or pandas DataFrame): Test set targets.\n",
    "    x_cols (list of strings): List of feature names.\n",
    "    y_cols (list of strings, optional): List of target names. Defaults to ['H/C', 'O/C', 'Oil_yield%', 'Gas_yield%', 'Char_yield%'].\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "  \"\"\"\n",
    "  #Initialize the model\n",
    "  model = MultiOutputRegressor(model_norm)\n",
    "  # Fit the model\n",
    "  model.fit(x_train, y_train)\n",
    "  # Fits the explainer\n",
    "  explainer = shap.KernelExplainer(model = model.predict, data = x_test, link = \"identity\")\n",
    "  # Get the shap values\n",
    "  shap_values = explainer.shap_values(X = x_test)\n",
    "  ##plot the summary plot\n",
    "  shap.summary_plot(shap_values = shap_values,\n",
    "                  features = x_test,\n",
    "                  feature_names=x_cols,\n",
    "                  class_names = y_cols,\n",
    "                  plot_size= (10,7),\n",
    "\n",
    "  )\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "def plot_partial_dependencies(model_norm,x_train,y_train,x_cols):\n",
    "    \"\"\"\n",
    "    Plot partial dependence plots for each output label and each input feature.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_norm: object\n",
    "        A normalized regression model\n",
    "    x_train: array-like\n",
    "        Training data features\n",
    "    y_train: array-like\n",
    "        Training data labels\n",
    "    x_cols: list\n",
    "        List of feature names\n",
    "    cols: list, optional (default=[i for i in range(14)])\n",
    "        List of feature indices to plot\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Define output label names\n",
    "    y_cols = ['H/C','O/C','Oil_yield%','Gas_yield%','Char_yield%']\n",
    "    x_train_df = pd.DataFrame(x_train,columns= x_cols)\n",
    "\n",
    "    # Iterate through each output label and plot partial dependence plots for each input feature\n",
    "    for i in range(len(y_cols)):\n",
    "        # Fit model to training data\n",
    "        model_norm.fit(x_train_df, y_train[:,i])\n",
    "\n",
    "        # Create figure and gridspec for subplots\n",
    "        fig = plt.figure(figsize=(18, 20))\n",
    "        gs = gridspec.GridSpec(len(x_cols),3, figure=fig)\n",
    "\n",
    "        # Create subplots\n",
    "        axs = [fig.add_subplot(gs[i]) for i in range(len(x_cols))]\n",
    "\n",
    "        # Plot partial dependence plots for each input feature\n",
    "        PartialDependenceDisplay.from_estimator(model_norm, x_train_df, x_train_df.columns, ax=axs)\n",
    "\n",
    "        # Adjust subplot spacing\n",
    "        fig.subplots_adjust(wspace=0.3,hspace=0.3)\n",
    "\n",
    "    # Adjust figure spacing\n",
    "    fig.tight_layout();\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "def evaluate_model(modelname,model,x_train,y_train,x_test, y_test,CV_folds,optimisation,param_grid):\n",
    "  \"\"\"\n",
    "  A function that evaluates the performance of each model\n",
    "\n",
    "  params:\n",
    "  ------\n",
    "  modelname: A str ['RF','ANN','GBR','XGBoost','SVM','AdaBoost']\n",
    "  model: Required model\n",
    "  x_train: A dataframe containing the training features/ Independent variable\n",
    "  y_train: A dataframe comtaining the training labels / Dependent variables\n",
    "  x_test: A dataframe containing the testing features/ Independent variable\n",
    "  y_test: A dataframe comtaining the testing labels / Dependent variables\n",
    "\n",
    "  return:\n",
    "  -------\n",
    "  Perf_sum: A dataframe containing the performance summary of the given model\n",
    "  y_test_pred: A dataframe containing the predicted labels\n",
    "\n",
    "  \"\"\"\n",
    "  perf_sum = pd.DataFrame(columns= ['R2_train', 'R2_test', 'RMSE_train', 'RMSE_test', 'MSE_train', 'MSE_test','R2_CV', 'RMSE_CV'],index=[0])\n",
    "\n",
    "  if modelname in ['RF','ANN']:\n",
    "    if optimisation:\n",
    "      simplefilter('ignore', category=FutureWarning) # turn depreciation warnings off\n",
    "      # Specify a hyper parameter tuning algorithm\n",
    "      tune_search = TuneSearchCV(\n",
    "          model,\n",
    "          param_grid,\n",
    "          search_optimization='hyperopt',\n",
    "          n_trials=10,\n",
    "          n_jobs=-1,\n",
    "          scoring={'RMSLE':'neg_mean_squared_error'},\n",
    "          cv=CV_folds,\n",
    "          refit='RMSLE',\n",
    "          verbose=1,\n",
    "          random_state=5\n",
    "          )\n",
    "      tune_search.fit(x_train, y_train)\n",
    "      ## Save the optimal hyper parmater values\n",
    "      best_cv_df.loc[best_cv_df['model']==modelname, 'best_hyper_param'] = str(tune_search.best_params_)\n",
    "      ## Save the CV results\n",
    "      cv_df = pd.DataFrame(tune_search.cv_results_)\n",
    "      cv_values = cv_df.loc[tune_search.best_index_, cv_df.columns.str.startswith('split')].values\n",
    "      best_cv_df.loc[best_cv_df['model']==modelname, 'RMSLE'] = cv_values[:5]\n",
    "\n",
    "      # Visualize the tuning results with parallel coordinate plot\n",
    "      tune_result_df = pd.concat([pd.DataFrame(tune_search.cv_results_['params']), cv_df.loc[:,cv_df.columns.str.startswith('mean')] ], axis=1)\n",
    "      best_parameters = tune_search.best_params_\n",
    "      #model = RandSearch_model.best_estimator_ # select best estimator as model for rest of code\n",
    "      model = tune_search.best_estimator_\n",
    "      simplefilter('ignore', category=FutureWarning) # turn depreciation warnings off\n",
    "      print(f'Best parameters for the model are {best_parameters}')\n",
    "\n",
    "    else:\n",
    "      # fit model\n",
    "      model.fit(x_train, y_train)\n",
    "      best_parameters = 'default'\n",
    "\n",
    "  if modelname in ['GBR','XGB','SVM','ADA','SGD']:\n",
    "    model = MultiOutputRegressor(model)\n",
    "    if optimisation:\n",
    "      simplefilter('ignore', category=FutureWarning) # turn depreciation warnings off\n",
    "      # Specify a hyper parameter tuning algorithm\n",
    "      tune_search = TuneSearchCV(\n",
    "          model,\n",
    "          param_grid,\n",
    "          search_optimization='hyperopt',\n",
    "          n_trials=10,\n",
    "          n_jobs=-1,\n",
    "          scoring={'RMSLE':'neg_mean_squared_error'},\n",
    "          cv=CV_folds,\n",
    "          refit='RMSLE',\n",
    "          verbose=1,\n",
    "          random_state=5\n",
    "          )\n",
    "\n",
    "      tune_search.fit(x_train, y_train)\n",
    "      ## Save the optimal hyper parmater values\n",
    "      best_cv_df.loc[best_cv_df['model']==modelname, 'best_hyper_param'] = str(tune_search.best_params_)\n",
    "      ## Save the CV results\n",
    "      cv_df = pd.DataFrame(tune_search.cv_results_)\n",
    "      cv_values = cv_df.loc[tune_search.best_index_, cv_df.columns.str.startswith('split')].values\n",
    "      best_cv_df.loc[best_cv_df['model']==modelname, 'RMSLE'] = cv_values[:5]\n",
    "\n",
    "      # Visualize the tuning results with parallel coordinate plot\n",
    "      tune_result_df = pd.concat([pd.DataFrame(tune_search.cv_results_['params']), cv_df.loc[:,cv_df.columns.str.startswith('mean')] ], axis=1)\n",
    "      best_parameters = tune_search.best_params_\n",
    "      model = tune_search.best_estimator_\n",
    "      simplefilter('ignore', category=FutureWarning) # turn depreciation warnings off\n",
    "      print(f'Best parameters for the model are {best_parameters}')\n",
    "    else:\n",
    "      # fit model\n",
    "      simplefilter('ignore', category=FutureWarning) # turn depreciation warnings off\n",
    "      simplefilter('ignore', category=ConvergenceWarning) # turn convergence warnings off\n",
    "      model = model.fit(x_train, y_train)\n",
    "      if modelname =='GBR' and x_train.shape[1] == 7:\n",
    "        # Download the trained model\n",
    "        filename = 'trained_gbrmodel.sav'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "      best_parameters = 'default'\n",
    "\n",
    "  # make predictions\n",
    "  y_train_pred = model.predict(x_train)\n",
    "  y_test_pred = model.predict(x_test)\n",
    "\n",
    "  # Evaluate performance - other performance measures can be shown with sorted(sklearn.metrics.SCORERS.keys())\n",
    "  R2_train = np.round(model.score(x_train, y_train),2)\n",
    "  R2_test = np.round(model.score(x_test, y_test),2)\n",
    "  # RMSE\n",
    "  RMSE_train = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "  RMSE_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "  # MSE\n",
    "  MSE_train = mean_squared_error(y_train, y_train_pred)\n",
    "  MSE_test = mean_squared_error(y_test, y_test_pred)\n",
    "  #MAE\n",
    "  MAE_train = mean_absolute_error(y_train, y_train_pred)\n",
    "  MAE_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "  # Evaluate cross validated performance on entire dataset. Combine datasets again before calculating cross validation scores\n",
    "\n",
    "  x_complete = pd.concat([pd.DataFrame(x_train), pd.DataFrame(x_test)],axis=0)\n",
    "  y_complete = pd.concat([pd.DataFrame(y_train), pd.DataFrame(y_test)],axis=0)\n",
    "\n",
    "  # Calculate cross validated scores\n",
    "  CV_R2_scores = cross_val_score(model, x_complete, y_complete, cv=CV_folds, scoring='r2')\n",
    "  R2_CV = np.mean(CV_R2_scores)\n",
    "  CV_RMSE_scores = -cross_val_score(model, x_complete, y_complete, cv=CV_folds, scoring='neg_root_mean_squared_error')\n",
    "  RMSE_CV = np.mean(CV_RMSE_scores)\n",
    "\n",
    "  # Store performance indicators and other information in dataframe:Performance measure (R2, RMSE, etc)\n",
    "  perf_sum['R2_train'] = R2_train\n",
    "  perf_sum['R2_test'] = R2_test\n",
    "  perf_sum['RMSE_train'] = RMSE_train\n",
    "  perf_sum['RMSE_test'] = RMSE_test\n",
    "  perf_sum['R2_CV'] = R2_CV\n",
    "  perf_sum['RMSE_CV'] = RMSE_CV\n",
    "  perf_sum['MSE_train'] = MSE_train\n",
    "  perf_sum['MSE_test'] = MSE_test\n",
    "  perf_sum['MAE_train'] = MAE_train\n",
    "  perf_sum['MAE_test'] = MAE_test\n",
    "\n",
    "  perf_sum[modelname] = modelname\n",
    "\n",
    "  return perf_sum,model,y_test_pred,y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one function which can fit any of the considered models with an range of possible pretreatment options\n",
    "def build_models(X, Y,test_fraction, modelname = 'RF', random_state = 42, CV_folds = 5, optimisation = False, display = True,x_cols=['Cel', 'Hem', 'Lig', 'Vm%', 'Ash%', 'FC%', 'C-%', 'H-%', 'O-%', 'N-%','Size','HR', 'PT', 'Temp'],graph=False ):\n",
    "    \"\"\"\n",
    "    Function to build models to be trained,tested and optimized.\n",
    "    A number of different ML algorithms are supported and may be defined by the variable 'modelname'.\n",
    "\n",
    "    Inputs:_cols\n",
    "    X - features/independent data for model training and testing\n",
    "    Y - labels(dependent data for model training and testing(multiple target columns possible)\n",
    "    predictor_pretreatment - specifies the predictor variable pretreatment option\n",
    "    target_pretreatment - specifies the target variable pretreatment option\n",
    "    modelname - defines model type (default: 'RF')\n",
    "    random_state - defines random seed (default: 42)\n",
    "    CV_folds - define number of cross validation folds (default: 5)\n",
    "    optimisation - specifies whether hyperparameter tuning is desired or default values are to be used (default: False)\n",
    "    iterations_RandSearch - specifies the number of iterations for randomised grid search. Higher values cover more combinations but take longer to compute. Should\n",
    "        be set to a higher value if number of combinations in optimisation grid is high (default: 100)\n",
    "    display = If True graphs and description of model training are shown. If False these won't be shown (default: True)\n",
    "    Output:\n",
    "    performance_summary - pandas dataframe containing trained models, performance measures, and more\n",
    "    \"\"\"\n",
    "    # Split data into train and test sets:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_fraction, random_state= random_state)\n",
    "    # --------------------------------------------------------------------------------------------------------------\n",
    "    param_grid = {}\n",
    "    # set maximum number of iterations to be used if the optimization is set to True\n",
    "    if optimisation == True:\n",
    "      print ('# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \\n') # to optimisation information from rest of model\n",
    "\n",
    "\n",
    "    if display == True:\n",
    "            print(modelname, 'model selected!\\n') # show which model has been selected\n",
    "            print ('# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \\n')\n",
    "\n",
    "    # Select which ML model is to be used and define grid/randomised search parameter grids for hyperparameter optimisation:\n",
    "    if modelname == 'RF': # Use sklearn's random forest regressor\n",
    "        model_norm = RandomForestRegressor(random_state= random_state)\n",
    "\n",
    "        # Define grid/randomised search parameters\n",
    "        max_depth = max_depth = [int(x) for x in np.linspace(10, 100, num = 10)]\n",
    "        max_depth.append(None)\n",
    "\n",
    "        param_grid = {\n",
    "        'n_estimators': [10, 50, 100, 200, 500, 1000, 2000],\n",
    "        'max_features': [1.0, 'sqrt'],\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        }\n",
    "\n",
    "        result,model,y_pred_data,y_train_pred = evaluate_model(modelname,model_norm,x_train,y_train,x_test, y_test,CV_folds,optimisation,param_grid)\n",
    "\n",
    "    elif modelname == 'GBR': # Use sklearn's gradient boosting regressor\n",
    "        model_norm = GradientBoostingRegressor(random_state= random_state)\n",
    "        # Define grid/randomised search parameters\n",
    "        param_grid= {\n",
    "        'estimator__loss': ['squared_error', 'absolute_error', 'huber'],\n",
    "        'estimator__learning_rate': [0.02, 0.05, 0.10, 0.15, 0.20, 0.50],\n",
    "        'estimator__n_estimators': [10, 50, 100, 200, 500, 1000, 2000],\n",
    "        'estimator__subsample': [0.6, 0.8, 1.0],\n",
    "        'estimator__min_samples_split': [2, 5, 10],\n",
    "        'estimator__min_samples_leaf': [1, 2, 4],\n",
    "        'estimator__max_depth': [2, 3, 5, 10],\n",
    "        'estimator__max_features': [1.0, 'sqrt', 0.3],\n",
    "        }\n",
    "\n",
    "        result,model,y_pred_data,y_train_pred = evaluate_model(modelname,model_norm, x_train,y_train,x_test, y_test,CV_folds,optimisation,param_grid)\n",
    "\n",
    "    elif modelname == 'XGB': # Use xgboost's extreme gradient boosting regressor\n",
    "        model_norm = XGBRegressor(verbosity=0,random_state=random_state)\n",
    "        simplefilter('ignore', category=FutureWarning) # turn depreciation warnings off\n",
    "        param_grid = {\n",
    "        'estimator__n_estimators': [10, 50, 100, 200, 500, 1000, 2000],\n",
    "        'estimator__max_depth': [2, 5, 7, 10,15,20,25],\n",
    "        'estimator__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'estimator__eta': [0.01, 0.1, 0.3],\n",
    "        'estimator__min_child_weight': [5, 10, 15],\n",
    "        'estimator__gamma': list(np.geomspace(1e-2, 1, 3)),\n",
    "        'estimator__subsample': [0.5, 0.7, 1],\n",
    "        'estimator__colsample_bytree': [0.5, 0.7, 1],\n",
    "        }\n",
    "\n",
    "        result,model,y_pred_data,y_train_pred = evaluate_model(modelname,model_norm, x_train,y_train,x_test, y_test,CV_folds,optimisation,param_grid)\n",
    "        simplefilter('ignore', category=FutureWarning) # turn depreciation warnings off\n",
    "\n",
    "    elif modelname == 'ADA': # Use sklearn's AdaBoost regressor\n",
    "        model_norm = AdaBoostRegressor(random_state= random_state)\n",
    "\n",
    "        # Define grid/randomised search parameters\n",
    "        base_estimator_depths = list() # define depth of decision tree stumps and base model\n",
    "        for i in range(1,10,2):\n",
    "            base_estimator_depths.insert(i, DecisionTreeRegressor(max_depth=i))\n",
    "\n",
    "        param_grid = {\n",
    "        'estimator__base_estimator': base_estimator_depths,\n",
    "        'estimator__n_estimators': [10, 50, 100, 200, 500, 1000, 2000],\n",
    "        'estimator__learning_rate': [0.2, 0.5, 1, 1.5, 2, 5],\n",
    "        'estimator__loss': ['linear', 'square', 'exponential']\n",
    "        }\n",
    "\n",
    "        result,model,y_pred_data,y_train_pred = evaluate_model(modelname,model_norm, x_train,y_train,x_test, y_test,CV_folds,optimisation,param_grid)\n",
    "\n",
    "    elif modelname == 'SVM': # Use sklearn's support vector machine\n",
    "        model_norm =  make_pipeline(MinMaxScaler(), SVR())\n",
    "\n",
    "        param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf','sigmoid','poly','linear']\n",
    "              }\n",
    "\n",
    "        # if optimisation == True:\n",
    "        #     print('Note: Optimisation currently not supported for SVM - change to \"False\" \\n')\n",
    "\n",
    "        result,model,y_pred_data,y_train_pred = evaluate_model(modelname,model_norm, x_train,y_train,x_test, y_test,CV_folds,optimisation,param_grid)\n",
    "\n",
    "    elif modelname == 'ANN': # Use sklearn's multi-layer perceptron\n",
    "        model_norm = make_pipeline(MinMaxScaler(),MLPRegressor(solver = 'lbfgs', random_state = random_state, early_stopping = True, max_iter = 1000))\n",
    "       # model = MLPRegressor(solver = 'lbfgs', random_state = random_state, early_stopping = True, max_iter = 1000)\n",
    "\n",
    "        param_grid = {\n",
    "        'mlpregressor__hidden_layer_sizes': [int(x) for x in np.linspace(3, 15, num = 7)],\n",
    "        'mlpregressor__activation': ['logistic', 'tanh', 'relu'],\n",
    "        'mlpregressor__solver': ['lbfgs', 'adam'],\n",
    "        'mlpregressor__early_stopping': [True, False],\n",
    "        'mlpregressor__max_iter': [2000] # 200, 500, 1000,\n",
    "        }\n",
    "        result,model,y_pred_data,y_train_pred = evaluate_model(modelname,model_norm, x_train,y_train,x_test, y_test,CV_folds,optimisation,param_grid)\n",
    "\n",
    "        simplefilter('ignore', category=ConvergenceWarning) # turn convergence warnings off\n",
    "\n",
    "    elif modelname == 'SGD':\n",
    "      model_norm = SGDRegressor()\n",
    "      param_grid = {\n",
    "    'estimator__alpha': list(np.geomspace(1e-7, 1e-3, 3)),\n",
    "    'estimator__epsilon': list(np.geomspace(1e-5, 1e-1, 3)),\n",
    "    'estimator__loss': ['huber', 'epsilon_insensitive'],\n",
    "    'estimator__tol': [1e-5, 1e-4, 1e-3],\n",
    "    'estimator__max_iter': [1000],\n",
    "      }\n",
    "\n",
    "      result,model,y_pred_data,y_train_pred = evaluate_model(modelname,model_norm, x_train,y_train,x_test, y_test,CV_folds,optimisation,param_grid)\n",
    "\n",
    "    else:\n",
    "        return ('Error: Model name not defined!')\n",
    "  # ----------------------------------\n",
    "  # Return outputs as a dataframe:\n",
    "\n",
    "    y_test_pred_df = pd.DataFrame(y_pred_data,columns=['H/C','O/C','Oil_yield%','Gas_yield%','Char_yield%'])\n",
    "    y_test_df = pd.DataFrame(y_test,columns=['H/C','O/C','Oil_yield%','Gas_yield%','Char_yield%'])\n",
    "    y_train_pred_df = pd.DataFrame(y_train_pred,columns=['H/C','O/C','Oil_yield%','Gas_yield%','Char_yield%'])\n",
    "    y_train_df = pd.DataFrame(y_train,columns=['H/C','O/C','Oil_yield%','Gas_yield%','Char_yield%'])\n",
    "\n",
    "    if graph:\n",
    "      plot_train_set(y_train_df,y_train_pred_df,y_test_df ,y_test_pred_df)\n",
    "      print('==========================================================================================================================================================')\n",
    "      print('==========================================================================================================================================================')\n",
    "      plot_feat_importance(model,y_train_df,x_cols)\n",
    "      print('==========================================================================================================================================================')\n",
    "      print('==========================================================================================================================================================')\n",
    "      plot_errors(y_train_df,y_train_pred_df,y_test_df ,y_test_pred_df)\n",
    "      print('==========================================================================================================================================================')\n",
    "      print('==========================================================================================================================================================')\n",
    "      plot_perm_feat_importance(model,y_train_df,x_cols,x_train,y_train)\n",
    "      print('==========================================================================================================================================================')\n",
    "      print('==========================================================================================================================================================')\n",
    "      if modelname == 'GBR':\n",
    "        plot_shap_importances(model_norm,x_train, x_test, y_train, y_test,x_cols)\n",
    "      print('===========================================================================================================================================================')\n",
    "      print('==========================================================================================================================================================')\n",
    "      plot_partial_dependencies(model_norm,x_train,y_train,x_cols)\n",
    "\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, Y = load_data('clean_data.xslx')\n",
    "# scale the data\n",
    "X,Y,mm_X,mm_Y = pre_scale_data(X,Y,'MS')\n",
    "# Remove outliers from data\n",
    "x_new, y_new = remove_outlier(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = build_models(x_new, y_new,test_fraction = 0.15, modelname = 'GBR', random_state = 42, CV_folds = 5, optimisation = False, display = True,graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the performance of all model before removing outliers and optimization set to false\n",
    "get_scores(X,Y,opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the performance of all model before removing outliers and optimization set to True\n",
    "get_scores(X,Y,opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### works if optimization is set to true, without removing outliers\n",
    "fig = px.box(best_cv_df, x='model', y='RMSLE', color='model', width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the performance of all model after removing outliers and optimization set to False\n",
    "get_scores(x_new,y_new,opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the performance of all model after removing outliers and optimization set to True\n",
    "get_scores(x_new,y_new,opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### works if optimization is set to true and outliers removed\n",
    "fig = px.box(best_cv_df, x='model', y='RMSLE', color='model', width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### After feature selection\n",
    "cols_str = ['Cel', 'Hem', 'Lig', 'Vm%', 'Ash%', 'FC%', 'C-%', 'H-%', 'O-%', 'N-%','Size', 'HR', 'PT', 'Temp']\n",
    "#cols = [2,3,7,8,9,11,12,13]\n",
    "cols = [2,4,8,7,9,10,12]\n",
    "x_cols = ['Lig','Ash%','O-%','H-%','N-%','Size','PT']\n",
    "X = X[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the performance of all model before removing outliers and optimization set to false\n",
    "get_scores(X,Y,opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the performance of all model before removing outliers and optimization set to True\n",
    "get_scores(X,Y,opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### works if optimization is set to true, without removing outliers\n",
    "fig = px.box(best_cv_df, x='model', y='RMSLE', color='model', width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the performance of all model after removing outliers and optimization set to False\n",
    "get_scores(x_new[:,cols],y_new,opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important columns\n",
    "cols = [2,4,8,7,9,10,12]\n",
    "#important features\n",
    "x_cols=['Lig','Ash%','O-%','H-%','N-%','Size','PT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = build_models(x_new[:,[2,4,8,7,9,10,12]], y_new,test_fraction = 0.15, modelname = 'GBR', random_state = 42, CV_folds = 5, optimisation = False, display = True,graph=True,x_cols=['Lig','Ash%','O-%','H-%','N-%','Size','PT'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
